{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"denseNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/mnansary/pyF2O/blob/master/colab_gen_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"1ojVYZ7Spzpv","colab_type":"text"},"source":["# colab specific task\n","*   mount google drive\n","*   change working directory to git repo\n","*   TPU check\n","\n"]},{"cell_type":"code","metadata":{"id":"xOI03Qu0tHrf","colab_type":"code","colab":{}},"source":["!pip3 install tensorflow==1.13.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"--q4JaV2ps6z","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsVhQoAOqGGW","colab_type":"code","colab":{}},"source":["cd /content/gdrive/My\\ Drive/PROJECTS/MED/pySKIND"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"692-uM-yqdaF","colab_type":"text"},"source":["## TPU Check"]},{"cell_type":"code","metadata":{"id":"JT9QkSiJqed6","colab_type":"code","colab":{}},"source":["import os\n","import pprint\n","import tensorflow as tf\n","\n","if 'COLAB_TPU_ADDR' not in os.environ:\n","  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n","else:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  print ('TPU address is', tpu_address)\n","\n","  with tf.Session(tpu_address) as session:\n","    devices = session.list_devices()\n","    \n","  print('TPU devices:')\n","  pprint.pprint(devices)\n","\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxefiHZ4qlHA","colab_type":"text"},"source":["# DenseNet Model Training\n","* Define **Parameters for training**\n","* Define **FLAGS for DenseNet**"]},{"cell_type":"markdown","metadata":{"id":"o2usCWY1Fc6E","colab_type":"text"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"Tdzez_PiFVTM","colab_type":"code","cellView":"both","outputId":"51090667-52ca-4975-df36-195403a3d3b2","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1574209093620,"user_tz":-360,"elapsed":103823,"user":{"displayName":"kugelblitz 1729","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJGep6QPYTWAq4UI7j5CR6IPsLtiU5CE9c8vIgsw=s64","userId":"14824418471120817982"}}},"source":["import sys\n","sys.path.append('.')\n","\n","from coreLib.utils import readh5\n","import numpy as np \n","class PARAMS:\n","    DS_DIR  = '/content/gdrive/My Drive/PROJECTS/MED/Train/' # @param\n","    BATCH_SIZE      = 128  # @param\n","    NUM_EPOCHS      = 100  # @param\n","    X_TRAIN_IDEN    = 'X_train.h5'  # @param\n","    Y_TRAIN_IDEN    = 'Y_train.h5'  # @param\n","    X_EVAL_IDEN     = 'X_eval.h5'  # @param\n","    Y_EVAL_IDEN     = 'Y_eval.h5'  # @param\n","    MODEL_DIR       = '/content/gdrive/My Drive/PROJECTS/MED/MODEL_DIR/' # @param\n","    MODEL_NAME      = 'denseNet' # @param\n","\n","X_train=readh5(os.path.join(PARAMS.DS_DIR,PARAMS.X_TRAIN_IDEN))\n","Y_train=readh5(os.path.join(PARAMS.DS_DIR,PARAMS.Y_TRAIN_IDEN))\n","X_eval=readh5(os.path.join(PARAMS.DS_DIR,PARAMS.X_EVAL_IDEN))\n","Y_eval=readh5(os.path.join(PARAMS.DS_DIR,PARAMS.Y_EVAL_IDEN))\n","\n","X_train=X_train.astype('float32')/255.0\n","X_eval=X_eval.astype('float32')/255.0\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","print(X_eval.shape)\n","print(Y_eval.shape)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(26624, 64, 64, 3)\n","(26624, 2)\n","(1024, 64, 64, 3)\n","(1024, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"blwtSzOarVYM","colab_type":"text"},"source":["### Compile Model"]},{"cell_type":"code","metadata":{"id":"BOro7D1krWYf","colab_type":"code","outputId":"ddad950a-e7af-4b6d-f7b1-e3cb3357e054","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1574209097213,"user_tz":-360,"elapsed":107407,"user":{"displayName":"kugelblitz 1729","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJGep6QPYTWAq4UI7j5CR6IPsLtiU5CE9c8vIgsw=s64","userId":"14824418471120817982"}}},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import categorical_crossentropy\n","from coreLib.models import DenseNet\n","\n","'''\n","resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_address)\n","tf.contrib.distribute.initialize_tpu_system(resolver)\n","strategy = tf.contrib.distribute.TPUStrategy(resolver)\n","with strategy.scope():\n","  >> code here for tf>1.13.1\n","'''\n","MODEL_OBJ=DenseNet(\n","                    image_dim=64,\n","                    nb_channels=3,\n","                    nb_classes=2,\n","                    nb_dense=3, # @param\n","                    nb_layers=12,# @param\n","                    nb_filter=12,# @param \n","                    growth_rate=12,# @param \n","                    weight_decay=None,# @param\n","                    dropout_rate=None,# @param\n","                    bottleneck=False,# @param\n","                    compression=0.5# @param\n","                   )\n","\n","model=MODEL_OBJ.get_model()\n","model.summary()\n","model.compile(optimizer=Adam(), \n","                loss=categorical_crossentropy,\n","                metrics=['accuracy'])\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","MODEL_INPUT (InputLayer)        (None, 64, 64, 3)    0                                            \n","__________________________________________________________________________________________________\n","INITAIAL_CONV2D_LAYER (Conv2D)  (None, 64, 64, 24)   648         MODEL_INPUT[0][0]                \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_1 (Bat (None, 64, 64, 24)   96          INITAIAL_CONV2D_LAYER[0][0]      \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_1 (Activatio (None, 64, 64, 24)   0           BATCH_NORM_BLOCK_1_LAYER_1[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_1 (Conv2D) (None, 64, 64, 12)   2592        RELU_BLOCK_1_LAYER_1[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_1 (Concate (None, 64, 64, 36)   0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_2 (Bat (None, 64, 64, 36)   144         CONCAT_BLOCK_1_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_2 (Activatio (None, 64, 64, 36)   0           BATCH_NORM_BLOCK_1_LAYER_2[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_2 (Conv2D) (None, 64, 64, 24)   7776        RELU_BLOCK_1_LAYER_2[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_2 (Concate (None, 64, 64, 60)   0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_3 (Bat (None, 64, 64, 60)   240         CONCAT_BLOCK_1_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_3 (Activatio (None, 64, 64, 60)   0           BATCH_NORM_BLOCK_1_LAYER_3[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_3 (Conv2D) (None, 64, 64, 36)   19440       RELU_BLOCK_1_LAYER_3[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_3 (Concate (None, 64, 64, 96)   0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_4 (Bat (None, 64, 64, 96)   384         CONCAT_BLOCK_1_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_4 (Activatio (None, 64, 64, 96)   0           BATCH_NORM_BLOCK_1_LAYER_4[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_4 (Conv2D) (None, 64, 64, 48)   41472       RELU_BLOCK_1_LAYER_4[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_4 (Concate (None, 64, 64, 144)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_5 (Bat (None, 64, 64, 144)  576         CONCAT_BLOCK_1_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_5 (Activatio (None, 64, 64, 144)  0           BATCH_NORM_BLOCK_1_LAYER_5[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_5 (Conv2D) (None, 64, 64, 60)   77760       RELU_BLOCK_1_LAYER_5[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_5 (Concate (None, 64, 64, 204)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_6 (Bat (None, 64, 64, 204)  816         CONCAT_BLOCK_1_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_6 (Activatio (None, 64, 64, 204)  0           BATCH_NORM_BLOCK_1_LAYER_6[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_6 (Conv2D) (None, 64, 64, 72)   132192      RELU_BLOCK_1_LAYER_6[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_6 (Concate (None, 64, 64, 276)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_7 (Bat (None, 64, 64, 276)  1104        CONCAT_BLOCK_1_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_7 (Activatio (None, 64, 64, 276)  0           BATCH_NORM_BLOCK_1_LAYER_7[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_7 (Conv2D) (None, 64, 64, 84)   208656      RELU_BLOCK_1_LAYER_7[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_7 (Concate (None, 64, 64, 360)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_8 (Bat (None, 64, 64, 360)  1440        CONCAT_BLOCK_1_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_8 (Activatio (None, 64, 64, 360)  0           BATCH_NORM_BLOCK_1_LAYER_8[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_8 (Conv2D) (None, 64, 64, 96)   311040      RELU_BLOCK_1_LAYER_8[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_8 (Concate (None, 64, 64, 456)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_9 (Bat (None, 64, 64, 456)  1824        CONCAT_BLOCK_1_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_9 (Activatio (None, 64, 64, 456)  0           BATCH_NORM_BLOCK_1_LAYER_9[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_9 (Conv2D) (None, 64, 64, 108)  443232      RELU_BLOCK_1_LAYER_9[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_9 (Concate (None, 64, 64, 564)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_10 (Ba (None, 64, 64, 564)  2256        CONCAT_BLOCK_1_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_10 (Activati (None, 64, 64, 564)  0           BATCH_NORM_BLOCK_1_LAYER_10[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_10 (Conv2D (None, 64, 64, 120)  609120      RELU_BLOCK_1_LAYER_10[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_10 (Concat (None, 64, 64, 684)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_11 (Ba (None, 64, 64, 684)  2736        CONCAT_BLOCK_1_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_11 (Activati (None, 64, 64, 684)  0           BATCH_NORM_BLOCK_1_LAYER_11[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_11 (Conv2D (None, 64, 64, 132)  812592      RELU_BLOCK_1_LAYER_11[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_11 (Concat (None, 64, 64, 816)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_1_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_1_LAYER_12 (Ba (None, 64, 64, 816)  3264        CONCAT_BLOCK_1_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_1_LAYER_12 (Activati (None, 64, 64, 816)  0           BATCH_NORM_BLOCK_1_LAYER_12[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_1_LAYER_12 (Conv2D (None, 64, 64, 144)  1057536     RELU_BLOCK_1_LAYER_12[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_1_LAYER_12 (Concat (None, 64, 64, 960)  0           INITAIAL_CONV2D_LAYER[0][0]      \n","                                                                 CONV2D_BLOCK_1_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_1_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_1_LAYER_11[0][0]    \n","                                                                 CONV2D_BLOCK_1_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_1_BATCH_NORM (Batch (None, 64, 64, 960)  3840        CONCAT_BLOCK_1_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_1_RELU (Activation) (None, 64, 64, 960)  0           TRANS_BLOCK_1_BATCH_NORM[0][0]   \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_1_CONV2D (Conv2D)   (None, 64, 64, 156)  149760      TRANS_BLOCK_1_RELU[0][0]         \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_1_AVGPOOL (AverageP (None, 32, 32, 156)  0           TRANS_BLOCK_1_CONV2D[0][0]       \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_1 (Bat (None, 32, 32, 156)  624         TRANS_BLOCK_1_AVGPOOL[0][0]      \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_1 (Activatio (None, 32, 32, 156)  0           BATCH_NORM_BLOCK_2_LAYER_1[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_1 (Conv2D) (None, 32, 32, 78)   109512      RELU_BLOCK_2_LAYER_1[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_1 (Concate (None, 32, 32, 234)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_2 (Bat (None, 32, 32, 234)  936         CONCAT_BLOCK_2_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_2 (Activatio (None, 32, 32, 234)  0           BATCH_NORM_BLOCK_2_LAYER_2[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_2 (Conv2D) (None, 32, 32, 90)   189540      RELU_BLOCK_2_LAYER_2[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_2 (Concate (None, 32, 32, 324)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_3 (Bat (None, 32, 32, 324)  1296        CONCAT_BLOCK_2_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_3 (Activatio (None, 32, 32, 324)  0           BATCH_NORM_BLOCK_2_LAYER_3[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_3 (Conv2D) (None, 32, 32, 102)  297432      RELU_BLOCK_2_LAYER_3[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_3 (Concate (None, 32, 32, 426)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_4 (Bat (None, 32, 32, 426)  1704        CONCAT_BLOCK_2_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_4 (Activatio (None, 32, 32, 426)  0           BATCH_NORM_BLOCK_2_LAYER_4[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_4 (Conv2D) (None, 32, 32, 114)  437076      RELU_BLOCK_2_LAYER_4[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_4 (Concate (None, 32, 32, 540)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_5 (Bat (None, 32, 32, 540)  2160        CONCAT_BLOCK_2_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_5 (Activatio (None, 32, 32, 540)  0           BATCH_NORM_BLOCK_2_LAYER_5[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_5 (Conv2D) (None, 32, 32, 126)  612360      RELU_BLOCK_2_LAYER_5[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_5 (Concate (None, 32, 32, 666)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_6 (Bat (None, 32, 32, 666)  2664        CONCAT_BLOCK_2_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_6 (Activatio (None, 32, 32, 666)  0           BATCH_NORM_BLOCK_2_LAYER_6[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_6 (Conv2D) (None, 32, 32, 138)  827172      RELU_BLOCK_2_LAYER_6[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_6 (Concate (None, 32, 32, 804)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_7 (Bat (None, 32, 32, 804)  3216        CONCAT_BLOCK_2_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_7 (Activatio (None, 32, 32, 804)  0           BATCH_NORM_BLOCK_2_LAYER_7[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_7 (Conv2D) (None, 32, 32, 150)  1085400     RELU_BLOCK_2_LAYER_7[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_7 (Concate (None, 32, 32, 954)  0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_8 (Bat (None, 32, 32, 954)  3816        CONCAT_BLOCK_2_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_8 (Activatio (None, 32, 32, 954)  0           BATCH_NORM_BLOCK_2_LAYER_8[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_8 (Conv2D) (None, 32, 32, 162)  1390932     RELU_BLOCK_2_LAYER_8[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_8 (Concate (None, 32, 32, 1116) 0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_9 (Bat (None, 32, 32, 1116) 4464        CONCAT_BLOCK_2_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_9 (Activatio (None, 32, 32, 1116) 0           BATCH_NORM_BLOCK_2_LAYER_9[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_9 (Conv2D) (None, 32, 32, 174)  1747656     RELU_BLOCK_2_LAYER_9[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_9 (Concate (None, 32, 32, 1290) 0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_10 (Ba (None, 32, 32, 1290) 5160        CONCAT_BLOCK_2_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_10 (Activati (None, 32, 32, 1290) 0           BATCH_NORM_BLOCK_2_LAYER_10[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_10 (Conv2D (None, 32, 32, 186)  2159460     RELU_BLOCK_2_LAYER_10[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_10 (Concat (None, 32, 32, 1476) 0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_11 (Ba (None, 32, 32, 1476) 5904        CONCAT_BLOCK_2_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_11 (Activati (None, 32, 32, 1476) 0           BATCH_NORM_BLOCK_2_LAYER_11[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_11 (Conv2D (None, 32, 32, 198)  2630232     RELU_BLOCK_2_LAYER_11[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_11 (Concat (None, 32, 32, 1674) 0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_2_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_2_LAYER_12 (Ba (None, 32, 32, 1674) 6696        CONCAT_BLOCK_2_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_2_LAYER_12 (Activati (None, 32, 32, 1674) 0           BATCH_NORM_BLOCK_2_LAYER_12[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_2_LAYER_12 (Conv2D (None, 32, 32, 210)  3163860     RELU_BLOCK_2_LAYER_12[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_2_LAYER_12 (Concat (None, 32, 32, 1884) 0           TRANS_BLOCK_1_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_2_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_2_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_2_LAYER_11[0][0]    \n","                                                                 CONV2D_BLOCK_2_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_2_BATCH_NORM (Batch (None, 32, 32, 1884) 7536        CONCAT_BLOCK_2_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_2_RELU (Activation) (None, 32, 32, 1884) 0           TRANS_BLOCK_2_BATCH_NORM[0][0]   \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_2_CONV2D (Conv2D)   (None, 32, 32, 222)  418248      TRANS_BLOCK_2_RELU[0][0]         \n","__________________________________________________________________________________________________\n","TRANS_BLOCK_2_AVGPOOL (AverageP (None, 16, 16, 222)  0           TRANS_BLOCK_2_CONV2D[0][0]       \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_1 (Bat (None, 16, 16, 222)  888         TRANS_BLOCK_2_AVGPOOL[0][0]      \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_1 (Activatio (None, 16, 16, 222)  0           BATCH_NORM_BLOCK_3_LAYER_1[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_1 (Conv2D) (None, 16, 16, 111)  221778      RELU_BLOCK_3_LAYER_1[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_1 (Concate (None, 16, 16, 333)  0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_2 (Bat (None, 16, 16, 333)  1332        CONCAT_BLOCK_3_LAYER_1[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_2 (Activatio (None, 16, 16, 333)  0           BATCH_NORM_BLOCK_3_LAYER_2[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_2 (Conv2D) (None, 16, 16, 123)  368631      RELU_BLOCK_3_LAYER_2[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_2 (Concate (None, 16, 16, 456)  0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_3 (Bat (None, 16, 16, 456)  1824        CONCAT_BLOCK_3_LAYER_2[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_3 (Activatio (None, 16, 16, 456)  0           BATCH_NORM_BLOCK_3_LAYER_3[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_3 (Conv2D) (None, 16, 16, 135)  554040      RELU_BLOCK_3_LAYER_3[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_3 (Concate (None, 16, 16, 591)  0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_4 (Bat (None, 16, 16, 591)  2364        CONCAT_BLOCK_3_LAYER_3[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_4 (Activatio (None, 16, 16, 591)  0           BATCH_NORM_BLOCK_3_LAYER_4[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_4 (Conv2D) (None, 16, 16, 147)  781893      RELU_BLOCK_3_LAYER_4[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_4 (Concate (None, 16, 16, 738)  0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_5 (Bat (None, 16, 16, 738)  2952        CONCAT_BLOCK_3_LAYER_4[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_5 (Activatio (None, 16, 16, 738)  0           BATCH_NORM_BLOCK_3_LAYER_5[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_5 (Conv2D) (None, 16, 16, 159)  1056078     RELU_BLOCK_3_LAYER_5[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_5 (Concate (None, 16, 16, 897)  0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_6 (Bat (None, 16, 16, 897)  3588        CONCAT_BLOCK_3_LAYER_5[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_6 (Activatio (None, 16, 16, 897)  0           BATCH_NORM_BLOCK_3_LAYER_6[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_6 (Conv2D) (None, 16, 16, 171)  1380483     RELU_BLOCK_3_LAYER_6[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_6 (Concate (None, 16, 16, 1068) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_7 (Bat (None, 16, 16, 1068) 4272        CONCAT_BLOCK_3_LAYER_6[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_7 (Activatio (None, 16, 16, 1068) 0           BATCH_NORM_BLOCK_3_LAYER_7[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_7 (Conv2D) (None, 16, 16, 183)  1758996     RELU_BLOCK_3_LAYER_7[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_7 (Concate (None, 16, 16, 1251) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_8 (Bat (None, 16, 16, 1251) 5004        CONCAT_BLOCK_3_LAYER_7[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_8 (Activatio (None, 16, 16, 1251) 0           BATCH_NORM_BLOCK_3_LAYER_8[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_8 (Conv2D) (None, 16, 16, 195)  2195505     RELU_BLOCK_3_LAYER_8[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_8 (Concate (None, 16, 16, 1446) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_9 (Bat (None, 16, 16, 1446) 5784        CONCAT_BLOCK_3_LAYER_8[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_9 (Activatio (None, 16, 16, 1446) 0           BATCH_NORM_BLOCK_3_LAYER_9[0][0] \n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_9 (Conv2D) (None, 16, 16, 207)  2693898     RELU_BLOCK_3_LAYER_9[0][0]       \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_9 (Concate (None, 16, 16, 1653) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_10 (Ba (None, 16, 16, 1653) 6612        CONCAT_BLOCK_3_LAYER_9[0][0]     \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_10 (Activati (None, 16, 16, 1653) 0           BATCH_NORM_BLOCK_3_LAYER_10[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_10 (Conv2D (None, 16, 16, 219)  3258063     RELU_BLOCK_3_LAYER_10[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_10 (Concat (None, 16, 16, 1872) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_11 (Ba (None, 16, 16, 1872) 7488        CONCAT_BLOCK_3_LAYER_10[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_11 (Activati (None, 16, 16, 1872) 0           BATCH_NORM_BLOCK_3_LAYER_11[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_11 (Conv2D (None, 16, 16, 231)  3891888     RELU_BLOCK_3_LAYER_11[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_11 (Concat (None, 16, 16, 2103) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_3_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_BLOCK_3_LAYER_12 (Ba (None, 16, 16, 2103) 8412        CONCAT_BLOCK_3_LAYER_11[0][0]    \n","__________________________________________________________________________________________________\n","RELU_BLOCK_3_LAYER_12 (Activati (None, 16, 16, 2103) 0           BATCH_NORM_BLOCK_3_LAYER_12[0][0]\n","__________________________________________________________________________________________________\n","CONV2D_BLOCK_3_LAYER_12 (Conv2D (None, 16, 16, 243)  4599261     RELU_BLOCK_3_LAYER_12[0][0]      \n","__________________________________________________________________________________________________\n","CONCAT_BLOCK_3_LAYER_12 (Concat (None, 16, 16, 2346) 0           TRANS_BLOCK_2_AVGPOOL[0][0]      \n","                                                                 CONV2D_BLOCK_3_LAYER_1[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_2[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_3[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_4[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_5[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_6[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_7[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_8[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_9[0][0]     \n","                                                                 CONV2D_BLOCK_3_LAYER_10[0][0]    \n","                                                                 CONV2D_BLOCK_3_LAYER_11[0][0]    \n","                                                                 CONV2D_BLOCK_3_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","BATCH_NORM_FINAL (BatchNormaliz (None, 16, 16, 2346) 9384        CONCAT_BLOCK_3_LAYER_12[0][0]    \n","__________________________________________________________________________________________________\n","FINAL_RELU (Activation)         (None, 16, 16, 2346) 0           BATCH_NORM_FINAL[0][0]           \n","__________________________________________________________________________________________________\n","GLOBAL_POOL (GlobalAveragePooli (None, 2346)         0           FINAL_RELU[0][0]                 \n","__________________________________________________________________________________________________\n","CLASS_DENSE (Dense)             (None, 2)            4694        GLOBAL_POOL[0][0]                \n","==================================================================================================\n","Total params: 41,832,704\n","Trainable params: 41,770,304\n","Non-trainable params: 62,400\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9nQXx8YRNSyr","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"OWTUQlweNYYN","colab_type":"code","outputId":"1b74a0ed-f0f8-4486-a7e7-11ff881a22cc","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#from tensorflow.keras.callbacks import ModelCheckpoint   \n","#checkpointer = ModelCheckpoint(filepath=os.path.join(PARAMS.MODEL_DIR,'{}.h5'.format(PARAMS.MODEL_NAME)), \n","                               #verbose=1, \n","                               #save_best_only=True)\n","TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","tf.logging.set_verbosity(tf.logging.INFO)\n","\n","model = tf.contrib.tpu.keras_to_tpu_model(model,\n","                                          strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n","history=model.fit(X_train,Y_train,\n","                  validation_data=(X_eval,Y_eval),\n","                  epochs=PARAMS.NUM_EPOCHS,\n","                  batch_size=PARAMS.BATCH_SIZE, \n","                  verbose=1)\n","#callbacks=[checkpointer],"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","INFO:tensorflow:Querying Tensorflow master (grpc://10.54.23.18:8470) for TPU system metadata.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13047164762070634554)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6597454410549484217)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8340505189229715248)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12683387582170140513)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13441517617839392952)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12283731854165827101)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14209654070803323468)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6893700225016749847)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10446599126649232301)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4348892694973092535)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13796428094455521304)\n","WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n","INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","Train on 26624 samples, validate on 1024 samples\n","Epoch 1/100\n","INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='MODEL_INPUT_10'), TensorSpec(shape=(16, 2), dtype=tf.float32, name='CLASS_DENSE_target_30')]\n","INFO:tensorflow:Overriding default placeholder.\n","INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","INFO:tensorflow:Remapping placeholder for MODEL_INPUT\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f806af44128> []\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Started compiling\n","INFO:tensorflow:Finished compiling. Time elapsed: 72.81516742706299 secs\n","INFO:tensorflow:Setting weights on TPU model.\n","INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n","INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n","INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n","INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n","WARNING:tensorflow:Cannot update non-variable config: epsilon\n","WARNING:tensorflow:Cannot update non-variable config: amsgrad\n","26496/26624 [============================>.] - ETA: 1s - loss: 0.6559 - acc: 0.6286INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='MODEL_INPUT_10'), TensorSpec(shape=(16, 2), dtype=tf.float32, name='CLASS_DENSE_target_30')]\n","INFO:tensorflow:Overriding default placeholder.\n","INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","INFO:tensorflow:Remapping placeholder for MODEL_INPUT\n","INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f8052fafd68> []\n","INFO:tensorflow:Started compiling\n","INFO:tensorflow:Finished compiling. Time elapsed: 29.441473722457886 secs\n","26624/26624 [==============================] - 283s 11ms/sample - loss: 0.6559 - acc: 0.6286 - val_loss: 0.7855 - val_acc: 0.4570\n","Epoch 2/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.6050 - acc: 0.6674 - val_loss: 0.8586 - val_acc: 0.5332\n","Epoch 3/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.5784 - acc: 0.6872 - val_loss: 0.7029 - val_acc: 0.6621\n","Epoch 4/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.5600 - acc: 0.7095 - val_loss: 0.7821 - val_acc: 0.6553\n","Epoch 5/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.5416 - acc: 0.7212 - val_loss: 5.5376 - val_acc: 0.5127\n","Epoch 6/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.5171 - acc: 0.7381 - val_loss: 1.0714 - val_acc: 0.6777\n","Epoch 7/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.4925 - acc: 0.7559 - val_loss: 1.1060 - val_acc: 0.5889\n","Epoch 8/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.4658 - acc: 0.7766 - val_loss: 0.6200 - val_acc: 0.7041\n","Epoch 9/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.4424 - acc: 0.7902 - val_loss: 0.4999 - val_acc: 0.7607\n","Epoch 10/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.4052 - acc: 0.8143 - val_loss: 2.4739 - val_acc: 0.5625\n","Epoch 11/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.3832 - acc: 0.8267 - val_loss: 0.8927 - val_acc: 0.7158\n","Epoch 12/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.3453 - acc: 0.8476 - val_loss: 0.3581 - val_acc: 0.8428\n","Epoch 13/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.3268 - acc: 0.8543 - val_loss: 0.5476 - val_acc: 0.7900\n","Epoch 14/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.2974 - acc: 0.8706 - val_loss: 2.1087 - val_acc: 0.6533\n","Epoch 15/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.2799 - acc: 0.8794 - val_loss: 1.2250 - val_acc: 0.6768\n","Epoch 16/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.2624 - acc: 0.8896 - val_loss: 0.3714 - val_acc: 0.8350\n","Epoch 17/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.2349 - acc: 0.9006 - val_loss: 0.3218 - val_acc: 0.8750\n","Epoch 18/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.2180 - acc: 0.9085 - val_loss: 0.4320 - val_acc: 0.8379\n","Epoch 19/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.2110 - acc: 0.9152 - val_loss: 0.8822 - val_acc: 0.7188\n","Epoch 20/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1847 - acc: 0.9266 - val_loss: 0.4445 - val_acc: 0.8486\n","Epoch 21/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1726 - acc: 0.9313 - val_loss: 0.4040 - val_acc: 0.8135\n","Epoch 22/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1579 - acc: 0.9384 - val_loss: 0.3319 - val_acc: 0.8809\n","Epoch 23/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1567 - acc: 0.9378 - val_loss: 0.3858 - val_acc: 0.8779\n","Epoch 24/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1341 - acc: 0.9496 - val_loss: 0.2140 - val_acc: 0.9014\n","Epoch 25/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1238 - acc: 0.9508 - val_loss: 0.2949 - val_acc: 0.8711\n","Epoch 26/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1269 - acc: 0.9524 - val_loss: 2.8570 - val_acc: 0.6484\n","Epoch 27/100\n","26624/26624 [==============================] - 87s 3ms/sample - loss: 0.1279 - acc: 0.9514 - val_loss: 0.4960 - val_acc: 0.8652\n","Epoch 28/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.1133 - acc: 0.9575 - val_loss: 0.2363 - val_acc: 0.9043\n","Epoch 29/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0971 - acc: 0.9629 - val_loss: 1.3222 - val_acc: 0.7754\n","Epoch 30/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0827 - acc: 0.9695 - val_loss: 0.3637 - val_acc: 0.8955\n","Epoch 31/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0864 - acc: 0.9681 - val_loss: 0.1457 - val_acc: 0.9492\n","Epoch 32/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0810 - acc: 0.9706 - val_loss: 1.1325 - val_acc: 0.7695\n","Epoch 33/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0728 - acc: 0.9743 - val_loss: 1.1250 - val_acc: 0.8027\n","Epoch 34/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0656 - acc: 0.9761 - val_loss: 0.2093 - val_acc: 0.9307\n","Epoch 35/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0840 - acc: 0.9681 - val_loss: 0.1638 - val_acc: 0.9521\n","Epoch 36/100\n","26624/26624 [==============================] - 88s 3ms/sample - loss: 0.0650 - acc: 0.9759 - val_loss: 0.3440 - val_acc: 0.8877\n","Epoch 37/100\n","13952/26624 [==============>...............] - ETA: 41s - loss: 0.0667 - acc: 0.9738"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nzx4-kyYbGfI","colab_type":"text"},"source":["### Save Model Weights"]},{"cell_type":"code","metadata":{"id":"t1iTz86KbNed","colab_type":"code","colab":{}},"source":["model.save_weights(os.path.join(PARAMS.MODEL_DIR,'{}_final.h5'.format(PARAMS.MODEL_NAME)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1M9sjHIbSnf","colab_type":"text"},"source":["### Plot Training Histoty"]},{"cell_type":"code","metadata":{"id":"ndNSS7XIbXaK","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('LOSS History')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(os.path.join(PARAMS.MODEL_DIR,'{}_history.png'.format(PARAMS.MODEL_NAME)))"],"execution_count":0,"outputs":[]}]}